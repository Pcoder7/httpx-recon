name: Parallel HTTPX Probe

on:
  workflow_dispatch:

permissions:
  contents: write

env:
  
  MAX_PARALLEL: 20         # <— throttle HTTPX jobs

jobs:
  prepare_matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set_matrix.outputs.matrix }}
      unique_domains: ${{ steps.set_matrix.outputs.unique_domains }}
    steps:
      - uses: actions/checkout@v3
        with: 
          fetch-depth: 0 

      - name: Build domain matrix from results/*/all_resolved.txt
        id: set_matrix
        run: |
          # 1. Discover domain folders with all_resolved.txt
          mapfile -t domains < <(
            find results -mindepth 1 -maxdepth 1 -type d \
              -exec test -f "{}/all_resolved.txt" \; -print \
            | sed 's|results/||'
          )
      
          # 2. If no domains are found, emit an empty matrix
          if [ ${#domains[@]} -eq 0 ]; then
            echo "No domains found under results/ — emitting empty matrix."
            echo "matrix<<EOF" >> $GITHUB_OUTPUT
            echo "[]"           >> $GITHUB_OUTPUT
            echo "EOF"          >> $GITHUB_OUTPUT
          else
            pairs=()
      
            for d in "${domains[@]}"; do
              SRC="results/$d/all_resolved.txt"

              # skip if file somehow missing  
              [ -f "$SRC" ] || continue
              
              # ← step A: get the total line count
              LINES=$(wc -l < "$SRC")
              echo "Source $SRC has $LINES lines"
      
              # 3. Create per-domain chunk dir & split into 100-line files
              CHUNK_DIR="results/$d/chunks"
              mkdir -p "$CHUNK_DIR"
              if [ "$LINES" -ge 200000 ]; then
                echo "— ≥200 000 lines: splitting into 50 equal chunks"
                split -n l/50 \
                      --numeric-suffixes=1 --suffix-length=2 --additional-suffix=.txt \
                      "$SRC" "$CHUNK_DIR/chunk_"
              elif [ "$LINES" -gt 1500 ]; then
                echo "— > 1500 lines: splitting into 20 equal chunks"
                split -n l/20 \
                      --numeric-suffixes=1 --suffix-length=2 --additional-suffix=.txt \
                      "$SRC" "$CHUNK_DIR/chunk_"
              else
                echo "— ≤ 1500 lines: splitting into 200-line chunks"
                split -l 200 \
                      --numeric-suffixes=1 --suffix-length=2 --additional-suffix=.txt \
                      "$SRC" "$CHUNK_DIR/chunk_"
              fi          
      
              # 4. Debug: list out what we just created
              echo "Contents of $CHUNK_DIR:"
              ls -R "$CHUNK_DIR" || echo "(none found)"
      
              # 5. Build a JSON pair for each chunk file
              for CH in "$CHUNK_DIR"/chunk_*; do
                pairs+=( "{\"domain\":\"$d\",\"chunk\":\"$CH\"}" )
              done
            done
      
            # 6. Emit the chunk-level matrix
            echo "matrix<<EOF" >> $GITHUB_OUTPUT
            printf '%s\n' "${pairs[@]}" | jq -s . >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi
      
          # 7. Emit the unique domain list (unchanged)
          domains_json=$(printf '%s\n' "${domains[@]}" | jq -R . | jq -s .)
          {
            echo "unique_domains<<EOF"
            echo "${domains_json}"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"    
                

      - name: Upload chunks artifact
        uses: actions/upload-artifact@v4
        with:
          name: httpx-chunks
          path: results/*/chunks/**
  
  httpx:
    needs: prepare_matrix
    runs-on: ubuntu-latest
    if: ${{ needs.prepare_matrix.outputs.matrix != '[]' }}
    strategy:
      fail-fast: false
      matrix:
        pair: ${{ fromJson(needs.prepare_matrix.outputs.matrix) }}
      max-parallel: 20

    steps:

      - name: Install GNU Parallel
        run: |
          sudo apt-get update
          sudo apt-get install -y parallel    
    
      - name: Setup Go (for go install)
        uses: actions/setup-go@v5
        with:
          go-version: '1.22'
          
      - uses: actions/checkout@v3
      - name: Create mod cache directory
        run: mkdir -p $HOME/go/pkg/mod
      
      - name: Cache Go binaries (httpx, anew)
        uses: actions/cache@v3
        with:
          path: |
            $HOME/go/pkg/mod
             ~/.cache/go-build
             $HOME/go/bin
          key: go-cache-${{ github.ref_name }} 
          restore-keys: |
            go-cache-
      
      - name: Ensure httpx & anew are installed
        run: |
         
          if ! command -v httpx >/dev/null; then
            go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
            echo "httpx installed"
            find $HOME -name httpx -type f
            echo "find actually found httpx path"
            
          else
            echo "httpx already cached"
          fi
          if ! command -v anew >/dev/null; then
            go install -v github.com/tomnomnom/anew@latest
            
          else
            echo "anew already cached"
          fi
          ls -R "results"
      
      - name: Download chunk files
        uses: actions/download-artifact@v4
        with: 
          name: httpx-chunks 
          path: results/
      
      #- name: List chunk files
       # run: |
        #  D="${{ matrix.pair.domain }}"
         # echo "Contents of results/${D}/chunks:"
          #ls -R "results/${D}/chunks"
      
      - name: Probe with httpx on ${{ matrix.pair.domain }}
        run: |
       
          D="${{ matrix.pair.domain }}"
          CH="${{ matrix.pair.chunk }}"
          OUT="results/${D}/httpx_out"
          mkdir -p "$OUT"
      
          LINES=$(wc -l < "$CH")
          echo "▶ Processing $CH — $LINES lines"

          if [ "$LINES" -le 1500 ]; then
            # small: single httpx run
            echo "— ≤1500 lines: single httpx with 100 threads"
            httpx -l "$CH" -silent -threads 100 \
              -o "${OUT}/httpx_$(basename "$CH").txt"

          else
            # big: split into 1500-line sub-files
            TMP=$(mktemp -d)
            # suffix-length=2 covers up to 99 subchunks (we’ll have ≤30)
            split -l 1500 --numeric-suffixes=1 --suffix-length=2 \
                  --additional-suffix=.txt \
                  "$CH" "$TMP/sub_"

            # decide parallelism & threads based on original chunk size
            if [ "$LINES" -gt 35000 ]; then
              JOBS=15; THREADS=250
            elif [ "$LINES" -gt 15000 ]; then
              JOBS=12; THREADS=200
            else
              # 1500 < LINES ≤ 15000 → split count up to ceil(LINES/2000), cap at 10
              SUBCOUNT=$(( (LINES + 1500 - 1) / 1500 ))
              if [ "$SUBCOUNT" -lt 10 ]; then
                JOBS=$SUBCOUNT
              else
                JOBS=8
              fi
              THREADS=100
            fi

            echo "— Launching parallel -j$JOBS with $THREADS threads"
            parallel -j"$JOBS" \
              httpx -l {} -silent -threads "$THREADS" -retries 1 -random-agent -timeout 10 \
                    -o "$OUT/httpx_{/.}.txt" \
              ::: "$TMP"/sub_*.txt

            # cleanup temp sub-chunks
            rm -rf "$TMP"
          fi


          # — now RECOMBINE all sub-results into one per original chunk:

          find "$OUT" -type f -name 'httpx_*.txt' -print0 \
            | xargs -0 cat \
            | sort -u > "${OUT}/httpx_$(basename "$CH").txt"
          
            
      - name: Compute per-chunk artifact name
        id: art
        run: |
          D="${{ matrix.pair.domain }}"
          CHN="$(basename "${{ matrix.pair.chunk }}")"
          # this writes an output called 'artifact_name'
          echo "artifact_name=httpx-${D}-${CHN}" >> $GITHUB_OUTPUT
          ANAME="httpx-${D}-${CHN}"
           # debug output so you can see it in the log
          echo ">> DEBUG: artifact_name is '$ANAME'"
            
          
      - name: Upload per‑chunk httpx results
        uses: actions/upload-artifact@v4
        env:
          ART_NAME: ${{ steps.art.outputs.artifact_name }}
        with:
          name: ${{ env.ART_NAME }}
          path: results/${{ matrix.pair.domain }}/httpx_out/*.txt


  aggregate_results:

    concurrency:
      group: aggregate-results-${{ matrix.domain }}
      cancel-in-progress: false
    needs: [prepare_matrix, httpx]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        domain: ${{ fromJson(needs.prepare_matrix.outputs.unique_domains) }}
    steps:
      - uses: actions/checkout@v3
        with: { fetch-depth: 0 }

      - name: Cache Go modules & binaries
        uses: actions/cache@v3
        with:
          path: |
            $HOME/go/pkg/mod
            ~/.cache/go-build
            $HOME/go/bin
          key: go-cache-${{ github.ref_name }}
          restore-keys: |
            go-cache-
      - name: Setup Go (for go install)
        uses: actions/setup-go@v5
        with:
          go-version: '1.22'       

      - name: Ensure anew is installed
        run: |
          if ! command -v anew >/dev/null; then
            echo "Installing anew…"
            go install github.com/tomnomnom/anew@latest
          else
            echo "anew already cached"
          fi          
      - name: Download all httpx artifacts
        uses: actions/download-artifact@v4
        with:
          path: results

      - name: Aggregate for ${{ matrix.domain }}
        run: |
          D="${{ matrix.domain }}"
          # make sure domain dir exists (matches chunks and recon)
          mkdir -p results/"$D"/httpx_out
          ls -A results
                            
          # cat only this domain’s httpx files
          # show how many lines we actually have across all the chunk files:

          echo "Total lines across chunks:"
          find results -type f -path "*/httpx-${D}-chunk_*.txt" -print0 | xargs -0 cat | tee >(wc -l)
          
          # now dedupe into one file
          
          echo "deduping files"
          find results -type f -path "*/httpx-${D}-chunk_*.txt" -print0 | xargs -0 cat | sort -u > results/"$D"/httpx_result.txt
          wc -l results/"$D"/httpx_result.txt


      - name: Commit & push HTTPX result for ${{ matrix.domain }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "actions@github.com"
          TARGET="results/${{ matrix.domain }}/httpx_result.txt"
      
          git add "$TARGET"
          git diff --cached --quiet || git commit -m "HTTPX result for ${{ matrix.domain }}"
      
          # Try a rebase for a linear history
          if ! git pull --rebase --autostash origin main; then
            echo "⚠️ Rebase failed (delete/modify conflict) — aborting and merging instead"
            git rebase --abort
            git pull origin main
          fi
      
          # Finally, push whatever we have (rebased or merged)
          git push origin HEAD:main
